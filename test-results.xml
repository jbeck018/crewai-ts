<?xml version="1.0" encoding="UTF-8" ?>
<testsuites name="vitest tests" tests="5" failures="0" errors="0" time="0.079768875">
    <testsuite name="tests/llm/LLMIntegration.test.ts" timestamp="2025-04-14T01:43:45.189Z" hostname="ip-192-168-0-220.ec2.internal" tests="5" failures="0" errors="0" skipped="0" time="0.079768875">
        <testcase classname="tests/llm/LLMIntegration.test.ts" name="LLM Integration &gt; LLM with TaskOutputFormatter &gt; should efficiently convert LLM output to structured data" time="0.0023175831">
        </testcase>
        <testcase classname="tests/llm/LLMIntegration.test.ts" name="LLM Integration &gt; LLM with TaskOutputFormatter &gt; should handle streaming output with minimal memory overhead" time="0.071853708">
        </testcase>
        <testcase classname="tests/llm/LLMIntegration.test.ts" name="LLM Integration &gt; Provider-specific optimizations &gt; should efficiently format OpenAI responses for task output" time="0.003359708">
        </testcase>
        <testcase classname="tests/llm/LLMIntegration.test.ts" name="LLM Integration &gt; Provider-specific optimizations &gt; should efficiently format Anthropic responses for task output" time="0.000807709">
        </testcase>
        <testcase classname="tests/llm/LLMIntegration.test.ts" name="LLM Integration &gt; Cache optimization benchmarks &gt; should demonstrate significant performance improvement with caching" time="0.0005985">
        </testcase>
    </testsuite>
</testsuites>
